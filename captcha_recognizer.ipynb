{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Terceiro Trabalho de Introdução à Computação Visual\n",
    "\n",
    "\n",
    "Arthur Pontes Nader <br>\n",
    "Luiz Philippe Pereira Amaral <br>\n",
    "Rita Rezende Borges de Lima"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instalação de bibliotecas e módulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Using cached opencv_python-4.6.0.66-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (60.9 MB)\n",
      "Requirement already satisfied: numpy>=1.14.5; python_version >= \"3.7\" in /mnt/c/Users/ritar/Documentos/UFMG/Quarto Periodo/Introdução a Computação Visual/venv_captcha/lib/python3.8/site-packages (from opencv-python) (1.23.0)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.6.0.66\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from tensorflow.keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pré Processamento\n",
    "\n",
    "\n",
    "Inicialmente declaramos a função ```char_to_int(x)```, que dado um caracter __x__, retorna seu valor inteiro correspondente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def char_to_int(x):\n",
    "    return {\"0\" : 0, \"1\" : 1, \"2\" : 2, \"3\" : 3, \"4\" : 4, \"5\" : 5, \"6\" : 6, \"7\" : 7, \"8\" : 8, \"9\" : 9, \\\n",
    "     \"A\" : 10, \"B\" : 11, \"C\" : 12, \"D\" : 13, \"E\" : 14, \"F\" : 15, \"G\" : 16, \"H\" : 17, \"I\" : 18,        \\\n",
    "     \"J\" : 19, \"K\" : 20, \"L\" : 21, \"M\" : 22, \"N\" : 23, \"O\" : 24, \"P\" : 25, \"Q\" : 26, \"R\" : 27,        \\\n",
    "     \"S\" : 28, \"T\" : 29, \"U\" : 30, \"V\" : 31, \"X\" : 32, \"W\" : 33, \"Y\" : 34, \"Z\" : 35, \"?\": 36}[x]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leitura de Dados \n",
    "\n",
    "Declaramos uma função ```get_labels()``` que tem como propósito ler um arquivo com o rótulo, e retornar este como uma lista de inteiros, para isso utiliza a função declarada previamente ```char_to_int()```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels(idx):\n",
    "\n",
    "    arq = open(\"CAPTCHA-10k/labels10k/\" + f\"{idx:06}\" + \".txt\", \"r\")\n",
    "    line = arq.readline()\n",
    "    arq.close()\n",
    "    \n",
    "    return [char_to_int(char) for char in line if char != \"\\n\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processamento da Imagem\n",
    "\n",
    "Em ambas as funções a seguir realizamos o processamento da imagem recebida como parâmetro, em ```image_preprocessing(img_path)``` fazemos a leitura da imagem, convertemos para gray scale, fazemos a binarização e aplicamos um blur com a mediana dos pixeis. De posse dessa imagem a função ```separate_image_characters(img)``` corta a imagem em 6 \"pedaços\", um para cada caracter e retorna estes em uma lista."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_processing(img_path):\n",
    "    \n",
    "    img = cv2.imread(img_path)\n",
    "    gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    bin_img = cv2.threshold(gray_img, 16, 255, cv2.THRESH_BINARY)[1]\n",
    "    img_median = cv2.medianBlur(bin_img, 5)\n",
    "    \n",
    "    return img_median \n",
    "\n",
    "def separate_image_characters(img):\n",
    "    \n",
    "    characters = []\n",
    "    \n",
    "    for j in range(10, img.shape[1], 30):\n",
    "        aux = img[:,j:j+30]\n",
    "        aux = cv2.resize(aux,(40,40))\n",
    "        aux = cv2.threshold(aux, 127, 255, cv2.THRESH_BINARY)[1]\n",
    "        aux = aux/255\n",
    "#         aux = aux.flatten()\n",
    "        characters.append(aux)\n",
    "        \n",
    "    return characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por fim implementamos o procedimento ```pre_processing(initial_range, final_range, dir_path)``` que para cada um dos arquivos faz sua leitura e chama as funções previamente implementadas e descritas para os conjuntos de dado de treinamento, validação e teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_processing(initial_range, final_range, dir_path):\n",
    "\n",
    "    x, y = [], []\n",
    "    for i in range(initial_range, final_range):\n",
    "        \n",
    "        labels = get_labels(i)\n",
    "        \n",
    "        img_path = dir_path + \"/\" + f\"{i:06}\" + \".jpg\" \n",
    "        img = image_processing(img_path)\n",
    "        img_characters = separate_image_characters(img)\n",
    "       \n",
    "        for idx in range(0, 6):\n",
    "            x.append(img_characters[idx])\n",
    "            y.append(labels[idx])\n",
    "            \n",
    "    return np.array(x, dtype=np.float32), np.array(y).reshape(len(y), 1)\n",
    "\n",
    "x_train, y_train = pre_processing(1, 8001, 'CAPTCHA-10k/treinamento')\n",
    "x_val, y_val = pre_processing(8001, 9001, 'CAPTCHA-10k/validacao')\n",
    "x_test, y_test = pre_processing(9001, 10001, 'CAPTCHA-10k/teste')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exemplo de dado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imagem 40x40\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O rótulo é: [27]\n"
     ]
    }
   ],
   "source": [
    "num = 0\n",
    "img = (x_train[num]*255) #.reshape((40,40))\n",
    "print(\"Imagem {}x{}\".format(len(img), len(img)))\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "print(\"O rótulo é:\", y_train[num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6000, 36) (48000, 37)\n"
     ]
    }
   ],
   "source": [
    "print(to_categorical(y_test).shape, to_categorical(y_train).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definição da Arquitetura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_22 (Conv2D)          (None, 40, 40, 32)        320       \n",
      "                                                                 \n",
      " conv2d_23 (Conv2D)          (None, 40, 40, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_11 (MaxPoolin  (None, 20, 20, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_21 (Dropout)        (None, 20, 20, 64)        0         \n",
      "                                                                 \n",
      " flatten_11 (Flatten)        (None, 25600)             0         \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 64)                1638464   \n",
      "                                                                 \n",
      " dropout_22 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 37)                2405      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,659,685\n",
      "Trainable params: 1,659,685\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "IMG_HEIGHT, IMG_WIDTH = 40, 40\n",
    "NUMBER_OF_LABELS = 37\n",
    "\n",
    "# Sequential layer\n",
    "model = Sequential()\n",
    "\n",
    "# CNN input layer\n",
    "model.add(Conv2D(32, (3, 3), strides=(1, 1), activation='relu', padding='same', input_shape=(IMG_HEIGHT,IMG_WIDTH, 1)))\n",
    "\n",
    "# hiden layers\n",
    "model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), padding='same'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# fully connected layer\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(NUMBER_OF_LABELS, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188/188 [==============================] - 232s 1s/step - loss: 2.5083 - accuracy: 0.2666 - val_loss: 0.9653 - val_accuracy: 0.7845\n"
     ]
    }
   ],
   "source": [
    "\n",
    "response = model.fit(\n",
    "            x_train, to_categorical(y = y_train, num_classes = NUMBER_OF_LABELS), \n",
    "            validation_data=(x_val, to_categorical(y_val, num_classes = NUMBER_OF_LABELS)),\n",
    "            batch_size=256, epochs=1, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node 'categorical_crossentropy/softmax_cross_entropy_with_logits' defined at (most recent call last):\n    File \"/usr/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/usr/lib/python3.8/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/mnt/c/Users/ritar/Documentos/UFMG/Quarto Periodo/Introdução a Computação Visual/venv_captcha/lib/python3.8/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/mnt/c/Users/ritar/Documentos/UFMG/Quarto Periodo/Introdução a Computação Visual/venv_captcha/lib/python3.8/site-packages/traitlets/config/application.py\", line 976, in launch_instance\n      app.start()\n    File \"/mnt/c/Users/ritar/Documentos/UFMG/Quarto Periodo/Introdução a Computação Visual/venv_captcha/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"/mnt/c/Users/ritar/Documentos/UFMG/Quarto Periodo/Introdução a Computação Visual/venv_captcha/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"/usr/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"/usr/lib/python3.8/asyncio/events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/mnt/c/Users/ritar/Documentos/UFMG/Quarto Periodo/Introdução a Computação Visual/venv_captcha/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"/mnt/c/Users/ritar/Documentos/UFMG/Quarto Periodo/Introdução a Computação Visual/venv_captcha/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"/mnt/c/Users/ritar/Documentos/UFMG/Quarto Periodo/Introdução a Computação Visual/venv_captcha/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"/mnt/c/Users/ritar/Documentos/UFMG/Quarto Periodo/Introdução a Computação Visual/venv_captcha/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"/mnt/c/Users/ritar/Documentos/UFMG/Quarto Periodo/Introdução a Computação Visual/venv_captcha/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"/mnt/c/Users/ritar/Documentos/UFMG/Quarto Periodo/Introdução a Computação Visual/venv_captcha/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/mnt/c/Users/ritar/Documentos/UFMG/Quarto Periodo/Introdução a Computação Visual/venv_captcha/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_cell\n      result = self._run_cell(\n    File \"/mnt/c/Users/ritar/Documentos/UFMG/Quarto Periodo/Introdução a Computação Visual/venv_captcha/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2936, in _run_cell\n      return runner(coro)\n    File \"/mnt/c/Users/ritar/Documentos/UFMG/Quarto Periodo/Introdução a Computação Visual/venv_captcha/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/mnt/c/Users/ritar/Documentos/UFMG/Quarto Periodo/Introdução a Computação Visual/venv_captcha/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3135, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/mnt/c/Users/ritar/Documentos/UFMG/Quarto Periodo/Introdução a Computação Visual/venv_captcha/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3338, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/mnt/c/Users/ritar/Documentos/UFMG/Quarto Periodo/Introdução a Computação Visual/venv_captcha/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3398, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_2329/3954641415.py\", line 1, in <cell line: 1>\n      score = model.evaluate(x_test, to_categorical(y_test), verbose=1)\n    File \"/mnt/c/Users/ritar/Documentos/UFMG/Quarto Periodo/Introdução a Computação Visual/venv_captcha/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/mnt/c/Users/ritar/Documentos/UFMG/Quarto Periodo/Introdução a Computação Visual/venv_captcha/lib/python3.8/site-packages/keras/engine/training.py\", line 1756, in evaluate\n      tmp_logs = self.test_function(iterator)\n    File \"/mnt/c/Users/ritar/Documentos/UFMG/Quarto Periodo/Introdução a Computação Visual/venv_captcha/lib/python3.8/site-packages/keras/engine/training.py\", line 1557, in test_function\n      return step_function(self, iterator)\n    File \"/mnt/c/Users/ritar/Documentos/UFMG/Quarto Periodo/Introdução a Computação Visual/venv_captcha/lib/python3.8/site-packages/keras/engine/training.py\", line 1546, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/mnt/c/Users/ritar/Documentos/UFMG/Quarto Periodo/Introdução a Computação Visual/venv_captcha/lib/python3.8/site-packages/keras/engine/training.py\", line 1535, in run_step\n      outputs = model.test_step(data)\n    File \"/mnt/c/Users/ritar/Documentos/UFMG/Quarto Periodo/Introdução a Computação Visual/venv_captcha/lib/python3.8/site-packages/keras/engine/training.py\", line 1501, in test_step\n      self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/mnt/c/Users/ritar/Documentos/UFMG/Quarto Periodo/Introdução a Computação Visual/venv_captcha/lib/python3.8/site-packages/keras/engine/training.py\", line 948, in compute_loss\n      return self.compiled_loss(\n    File \"/mnt/c/Users/ritar/Documentos/UFMG/Quarto Periodo/Introdução a Computação Visual/venv_captcha/lib/python3.8/site-packages/keras/engine/compile_utils.py\", line 201, in __call__\n      loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/mnt/c/Users/ritar/Documentos/UFMG/Quarto Periodo/Introdução a Computação Visual/venv_captcha/lib/python3.8/site-packages/keras/losses.py\", line 139, in __call__\n      losses = call_fn(y_true, y_pred)\n    File \"/mnt/c/Users/ritar/Documentos/UFMG/Quarto Periodo/Introdução a Computação Visual/venv_captcha/lib/python3.8/site-packages/keras/losses.py\", line 243, in call\n      return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/mnt/c/Users/ritar/Documentos/UFMG/Quarto Periodo/Introdução a Computação Visual/venv_captcha/lib/python3.8/site-packages/keras/losses.py\", line 1787, in categorical_crossentropy\n      return backend.categorical_crossentropy(\n    File \"/mnt/c/Users/ritar/Documentos/UFMG/Quarto Periodo/Introdução a Computação Visual/venv_captcha/lib/python3.8/site-packages/keras/backend.py\", line 5134, in categorical_crossentropy\n      return tf.nn.softmax_cross_entropy_with_logits(\nNode: 'categorical_crossentropy/softmax_cross_entropy_with_logits'\nlogits and labels must be broadcastable: logits_size=[32,37] labels_size=[32,36]\n\t [[{{node categorical_crossentropy/softmax_cross_entropy_with_logits}}]] [Op:__inference_test_function_10781]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Input \u001b[0;32mIn [72]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m score \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_categorical\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(score)\n",
      "File \u001b[0;32m/mnt/c/Users/ritar/Documentos/UFMG/Quarto Periodo/Introdução a Computação Visual/venv_captcha/lib/python3.8/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/mnt/c/Users/ritar/Documentos/UFMG/Quarto Periodo/Introdução a Computação Visual/venv_captcha/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'categorical_crossentropy/softmax_cross_entropy_with_logits' defined at (most recent call last):\n    File \"/usr/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/usr/lib/python3.8/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/mnt/c/Users/ritar/Documentos/UFMG/Quarto Periodo/Introdução a Computação Visual/venv_captcha/lib/python3.8/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/mnt/c/Users/ritar/Documentos/UFMG/Quarto Periodo/Introdução a Computação Visual/venv_captcha/lib/python3.8/site-packages/traitlets/config/application.py\", line 976, in launch_instance\n      app.start()\n    File \"/mnt/c/Users/ritar/Documentos/UFMG/Quarto Periodo/Introdução a Computação Visual/venv_captcha/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"/mnt/c/Users/ritar/Documentos/UFMG/Quarto Periodo/Introdução a Computação Visual/venv_captcha/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"/usr/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"/usr/lib/python3.8/asyncio/events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/mnt/c/Users/ritar/Documentos/UFMG/Quarto Periodo/Introdução a Computação Visual/venv_captcha/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"/mnt/c/Users/ritar/Documentos/UFMG/Quarto Periodo/Introdução a Computação Visual/venv_captcha/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"/mnt/c/Users/ritar/Documentos/UFMG/Quarto Periodo/Introdução a Computação Visual/venv_captcha/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"/mnt/c/Users/ritar/Documentos/UFMG/Quarto Periodo/Introdução a Computação Visual/venv_captcha/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"/mnt/c/Users/ritar/Documentos/UFMG/Quarto Periodo/Introdução a Computação Visual/venv_captcha/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"/mnt/c/Users/ritar/Documentos/UFMG/Quarto Periodo/Introdução a Computação Visual/venv_captcha/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/mnt/c/Users/ritar/Documentos/UFMG/Quarto Periodo/Introdução a Computação Visual/venv_captcha/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_cell\n      result = self._run_cell(\n    File \"/mnt/c/Users/ritar/Documentos/UFMG/Quarto Periodo/Introdução a Computação Visual/venv_captcha/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2936, in _run_cell\n      return runner(coro)\n    File \"/mnt/c/Users/ritar/Documentos/UFMG/Quarto Periodo/Introdução a Computação Visual/venv_captcha/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/mnt/c/Users/ritar/Documentos/UFMG/Quarto Periodo/Introdução a Computação Visual/venv_captcha/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3135, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/mnt/c/Users/ritar/Documentos/UFMG/Quarto Periodo/Introdução a Computação Visual/venv_captcha/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3338, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/mnt/c/Users/ritar/Documentos/UFMG/Quarto Periodo/Introdução a Computação Visual/venv_captcha/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3398, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_2329/3954641415.py\", line 1, in <cell line: 1>\n      score = model.evaluate(x_test, to_categorical(y_test), verbose=1)\n    File \"/mnt/c/Users/ritar/Documentos/UFMG/Quarto Periodo/Introdução a Computação Visual/venv_captcha/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/mnt/c/Users/ritar/Documentos/UFMG/Quarto Periodo/Introdução a Computação Visual/venv_captcha/lib/python3.8/site-packages/keras/engine/training.py\", line 1756, in evaluate\n      tmp_logs = self.test_function(iterator)\n    File \"/mnt/c/Users/ritar/Documentos/UFMG/Quarto Periodo/Introdução a Computação Visual/venv_captcha/lib/python3.8/site-packages/keras/engine/training.py\", line 1557, in test_function\n      return step_function(self, iterator)\n    File \"/mnt/c/Users/ritar/Documentos/UFMG/Quarto Periodo/Introdução a Computação Visual/venv_captcha/lib/python3.8/site-packages/keras/engine/training.py\", line 1546, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/mnt/c/Users/ritar/Documentos/UFMG/Quarto Periodo/Introdução a Computação Visual/venv_captcha/lib/python3.8/site-packages/keras/engine/training.py\", line 1535, in run_step\n      outputs = model.test_step(data)\n    File \"/mnt/c/Users/ritar/Documentos/UFMG/Quarto Periodo/Introdução a Computação Visual/venv_captcha/lib/python3.8/site-packages/keras/engine/training.py\", line 1501, in test_step\n      self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/mnt/c/Users/ritar/Documentos/UFMG/Quarto Periodo/Introdução a Computação Visual/venv_captcha/lib/python3.8/site-packages/keras/engine/training.py\", line 948, in compute_loss\n      return self.compiled_loss(\n    File \"/mnt/c/Users/ritar/Documentos/UFMG/Quarto Periodo/Introdução a Computação Visual/venv_captcha/lib/python3.8/site-packages/keras/engine/compile_utils.py\", line 201, in __call__\n      loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/mnt/c/Users/ritar/Documentos/UFMG/Quarto Periodo/Introdução a Computação Visual/venv_captcha/lib/python3.8/site-packages/keras/losses.py\", line 139, in __call__\n      losses = call_fn(y_true, y_pred)\n    File \"/mnt/c/Users/ritar/Documentos/UFMG/Quarto Periodo/Introdução a Computação Visual/venv_captcha/lib/python3.8/site-packages/keras/losses.py\", line 243, in call\n      return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/mnt/c/Users/ritar/Documentos/UFMG/Quarto Periodo/Introdução a Computação Visual/venv_captcha/lib/python3.8/site-packages/keras/losses.py\", line 1787, in categorical_crossentropy\n      return backend.categorical_crossentropy(\n    File \"/mnt/c/Users/ritar/Documentos/UFMG/Quarto Periodo/Introdução a Computação Visual/venv_captcha/lib/python3.8/site-packages/keras/backend.py\", line 5134, in categorical_crossentropy\n      return tf.nn.softmax_cross_entropy_with_logits(\nNode: 'categorical_crossentropy/softmax_cross_entropy_with_logits'\nlogits and labels must be broadcastable: logits_size=[32,37] labels_size=[32,36]\n\t [[{{node categorical_crossentropy/softmax_cross_entropy_with_logits}}]] [Op:__inference_test_function_10781]"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, to_categorical(y_test), verbose=1)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "(6000,)\n"
     ]
    }
   ],
   "source": [
    "print(to_categorical(y_test))\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
